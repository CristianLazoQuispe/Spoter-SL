program: train.py
method: grid
parameters:
  experiment_name:
    values: [original_bmean4_losswe.001_no_smot_si_squared2_plateu]
  sweep:
    values: [1]
  lr:
    values: [0.001] #0.001, 0.00001,
  num_heads:
    values: [3,27] # [54,27,9,3,1] 27,18,9,6,3,2,1] este debe ser un divisor de hidden_dim
  num_layers_1:
    values: [9,27] # [64,12,8,6,4,2,1]
  num_layers_2:
    values: [3,27] # [128,64,32,16,4,,64,12,8,6,4,2,1] # self.transformer.decoder.num_layers
  dim_feedforward:
    values: [64,128] #
  device:
    values: [0]
  augmentation:
    values: [0]
  factor_aug:
    values: [1]
  batch_mean:
    values: [1]
  batch_size:
    values: [4]
  is_weighted:
    values: [1]
  label_smoothing:
    values: [0]
  early_stopping_patience:
    values: [500]
  epochs:
    values: [50000]
  is_weighted_squared:
    values: [1]
  weighted_squared:
    values: [2]
  scheduler:
    values: ["plateu"]

#python train.py --device=0 --dim_feedforward=128 --lr=0.0001 --num_heads=54 --num_layers_1=32 --num_layers_2=256 --sweep=1 --augmentation=1
