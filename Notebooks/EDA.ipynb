{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da960ca-d2ef-49b9-9e6f-acbf5bea4978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cc/Gloss/Spoter-SL\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a2733b7-94aa-4740-9972-13c2d5c00ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from Src.datasets.Spoter_dataloader import LSP_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from Src.datasets.Spoter_dataloader_aug import AugmentedDataLoader\n",
    "from Src.spoter.gaussian_noise import GaussianNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "098c18c8-1133-49a0-9437-e99b45f85218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aa48452-d15a-4c2b-ab88-243b6f3827a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 379\n",
    "\n",
    "gaussian_mean = 0\n",
    "gaussian_std = 0.1\n",
    "augmentation = True\n",
    "\n",
    "factor_aug = 0\n",
    "training_set_path   = \"../SL_ConnectingPoints/split/DGI305-AEC--38--incremental--mediapipe_n_folds_5_seed_1_klod_1-Train.hdf5\"\n",
    "validation_set_path= \"../SL_ConnectingPoints/split/DGI305-AEC--38--incremental--mediapipe_n_folds_5_seed_1_klod_1-Val.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8a12ea-7023-4575-981f-3788f2dd2fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9be779cd10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize all the random seeds\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b33459b6-afe8-455e-ba90-9ca89b9834f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8470c75e-decc-461a-b6da-846782bfc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([GaussianNoise(gaussian_mean, gaussian_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a70c51f9-8a0e-4dab-bea8-7ef9face63c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "********************\n",
      "Use keypoint model :  mediapipe\n",
      "self.list_labels_banned []\n",
      "path                       : ../SL_ConnectingPoints/split/DGI305-AEC--38--incremental--mediapipe_n_folds_5_seed_1_klod_1-Train.hdf5\n",
      "keypoints_model            : mediapipe\n",
      "landmarks_ref              : Data/Mapeo landmarks librerias.csv\n",
      "threshold_frecuency_labels : 0\n",
      "list_labels_banned         : []\n",
      "Use keypoint model :  mediapipe\n",
      "use column for index keypoint : mp_indexInArray\n",
      " using keypoints_number: 54\n",
      "section_keypoints :  54  -- uniques:  54\n",
      "name_keypoints    :  54  -- uniques:  33\n",
      "idx_keypoints     :  54  -- uniques:  54\n",
      "\n",
      "section_keypoints used:\n",
      "['pose_nose' 'pose_left_eye' 'pose_right_eye' 'pose_left_ear'\n",
      " 'pose_right_ear' 'pose_left_shoulder' 'pose_right_shoulder'\n",
      " 'pose_left_elbow' 'pose_right_elbow' 'pose_left_wrist' 'pose_right_wrist'\n",
      " 'leftHand_wrist' 'leftHand_thumb_cmc' 'leftHand_thumb_mcp'\n",
      " 'leftHand_thumb_ip' 'leftHand_thumb_tip' 'leftHand_index_finger_mcp'\n",
      " 'leftHand_index_finger_pip' 'leftHand_index_finger_dip'\n",
      " 'leftHand_index_finger_tip' 'leftHand_middle_finger_mcp'\n",
      " 'leftHand_middle_finger_pip' 'leftHand_middle_finger_dip'\n",
      " 'leftHand_middle_finger_tip' 'leftHand_ring_finger_mcp'\n",
      " 'leftHand_ring_finger_pip' 'leftHand_ring_finger_dip'\n",
      " 'leftHand_ring_finger_tip' 'leftHand_pinky_mcp' 'leftHand_pinky_pip'\n",
      " 'leftHand_pinky_dip' 'leftHand_pinky_tip' 'rightHand_wrist'\n",
      " 'rightHand_thumb_cmc' 'rightHand_thumb_mcp' 'rightHand_thumb_ip'\n",
      " 'rightHand_thumb_tip' 'rightHand_index_finger_mcp'\n",
      " 'rightHand_index_finger_pip' 'rightHand_index_finger_dip'\n",
      " 'rightHand_index_finger_tip' 'rightHand_middle_finger_mcp'\n",
      " 'rightHand_middle_finger_pip' 'rightHand_middle_finger_dip'\n",
      " 'rightHand_middle_finger_tip' 'rightHand_ring_finger_mcp'\n",
      " 'rightHand_ring_finger_pip' 'rightHand_ring_finger_dip'\n",
      " 'rightHand_ring_finger_tip' 'rightHand_pinky_mcp' 'rightHand_pinky_pip'\n",
      " 'rightHand_pinky_dip' 'rightHand_pinky_tip' 'pose_chest_middle_up']\n",
      "Reading dataset .. \n",
      "Total size dataset :  744\n",
      "Keys in dataset: <KeysViewHDF5 ['0', '1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '2', '20', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '21', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '22', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '23', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '24', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '25', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '26', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '27', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '28', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '29', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '3', '30', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '31', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '32', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '33', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '34', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '35', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '36', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '37', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '38', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '39', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '4', '40', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '41', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '42', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '43', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '44', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '45', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '46', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '47', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '48', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '49', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '5', '50', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '51', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '52', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '53', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '54', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '55', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '56', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '57', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '58', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '59', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '6', '60', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '61', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '62', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '63', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '64', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '65', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '66', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '67', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '68', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '69', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '7', '70', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '71', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '72', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '73', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '74', '740', '741', '742', '743', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████████████▎                                                                                                                       | 134/744 [00:00<00:00, 1338.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size video :  (19, 544, 2) -- label :  ESPERAR\n",
      "filtering by keypoints idx .. \n",
      "filtered size video :  (19, 54, 2) -- label :  ESPERAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 744/744 [00:00<00:00, 1353.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frecuency labels filtering ...\n",
      "hist counter\n",
      "{'ESPERAR': 15, 'OYE': 14, 'VER': 36, 'YO': 36, 'DINERO': 12, 'CUANTO': 13, 'DENTRO': 16, 'UNO': 25, 'CAMINAR-PERSONA': 21, 'MI': 16, 'IDEA': 14, 'IGUAL': 29, 'HOY': 14, 'NIÑO': 17, 'DORMIR': 16, 'AHORA': 20, 'YA': 20, 'SOL': 11, 'DOS': 33, 'GUARDAR': 14, 'BIEN': 36, 'AMIGO': 13, 'DECIR': 27, 'IR': 22, 'HACER': 16, 'HOLA': 9, 'ESCRIBIR': 12, 'SENTIR': 12, 'PENSAR': 29, 'COMPRAR': 13, 'NO': 32, 'CASA': 13, 'CIEN': 28, 'SABER': 12, 'COMER': 36, 'AYUDAR': 12, 'QUÉ': 13, 'TRES': 17}\n",
      "sorted(set(labels_dataset))  :  ['AHORA', 'AMIGO', 'AYUDAR', 'BIEN', 'CAMINAR-PERSONA', 'CASA', 'CIEN', 'COMER', 'COMPRAR', 'CUANTO', 'DECIR', 'DENTRO', 'DINERO', 'DORMIR', 'DOS', 'ESCRIBIR', 'ESPERAR', 'GUARDAR', 'HACER', 'HOLA', 'HOY', 'IDEA', 'IGUAL', 'IR', 'MI', 'NIÑO', 'NO', 'OYE', 'PENSAR', 'QUÉ', 'SABER', 'SENTIR', 'SOL', 'TRES', 'UNO', 'VER', 'YA', 'YO']\n",
      "dict_labels_dataset      : {'AHORA': 0, 'AMIGO': 1, 'AYUDAR': 2, 'BIEN': 3, 'CAMINAR-PERSONA': 4, 'CASA': 5, 'CIEN': 6, 'COMER': 7, 'COMPRAR': 8, 'CUANTO': 9, 'DECIR': 10, 'DENTRO': 11, 'DINERO': 12, 'DORMIR': 13, 'DOS': 14, 'ESCRIBIR': 15, 'ESPERAR': 16, 'GUARDAR': 17, 'HACER': 18, 'HOLA': 19, 'HOY': 20, 'IDEA': 21, 'IGUAL': 22, 'IR': 23, 'MI': 24, 'NIÑO': 25, 'NO': 26, 'OYE': 27, 'PENSAR': 28, 'QUÉ': 29, 'SABER': 30, 'SENTIR': 31, 'SOL': 32, 'TRES': 33, 'UNO': 34, 'VER': 35, 'YA': 36, 'YO': 37}\n",
      "inv_dict_labels_dataset  : {0: 'AHORA', 1: 'AMIGO', 2: 'AYUDAR', 3: 'BIEN', 4: 'CAMINAR-PERSONA', 5: 'CASA', 6: 'CIEN', 7: 'COMER', 8: 'COMPRAR', 9: 'CUANTO', 10: 'DECIR', 11: 'DENTRO', 12: 'DINERO', 13: 'DORMIR', 14: 'DOS', 15: 'ESCRIBIR', 16: 'ESPERAR', 17: 'GUARDAR', 18: 'HACER', 19: 'HOLA', 20: 'HOY', 21: 'IDEA', 22: 'IGUAL', 23: 'IR', 24: 'MI', 25: 'NIÑO', 26: 'NO', 27: 'OYE', 28: 'PENSAR', 29: 'QUÉ', 30: 'SABER', 31: 'SENTIR', 32: 'SOL', 33: 'TRES', 34: 'UNO', 35: 'VER', 36: 'YA', 37: 'YO'}\n",
      "encoded_dataset: 744\n",
      "label encoding completed!\n",
      "total unique labels :  38\n",
      "Reading dataset completed!\n",
      "{'pose': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 53], 'left_hand': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], 'rigth_hand': [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]} {'pose_nose': 0, 'pose_left_eye': 1, 'pose_right_eye': 2, 'pose_left_ear': 3, 'pose_right_ear': 4, 'pose_left_shoulder': 5, 'pose_right_shoulder': 6, 'pose_left_elbow': 7, 'pose_right_elbow': 8, 'pose_left_wrist': 9, 'pose_right_wrist': 10, 'leftHand_wrist': 11, 'leftHand_thumb_cmc': 12, 'leftHand_thumb_mcp': 13, 'leftHand_thumb_ip': 14, 'leftHand_thumb_tip': 15, 'leftHand_index_finger_mcp': 16, 'leftHand_index_finger_pip': 17, 'leftHand_index_finger_dip': 18, 'leftHand_index_finger_tip': 19, 'leftHand_middle_finger_mcp': 20, 'leftHand_middle_finger_pip': 21, 'leftHand_middle_finger_dip': 22, 'leftHand_middle_finger_tip': 23, 'leftHand_ring_finger_mcp': 24, 'leftHand_ring_finger_pip': 25, 'leftHand_ring_finger_dip': 26, 'leftHand_ring_finger_tip': 27, 'leftHand_pinky_mcp': 28, 'leftHand_pinky_pip': 29, 'leftHand_pinky_dip': 30, 'leftHand_pinky_tip': 31, 'rightHand_wrist': 32, 'rightHand_thumb_cmc': 33, 'rightHand_thumb_mcp': 34, 'rightHand_thumb_ip': 35, 'rightHand_thumb_tip': 36, 'rightHand_index_finger_mcp': 37, 'rightHand_index_finger_pip': 38, 'rightHand_index_finger_dip': 39, 'rightHand_index_finger_tip': 40, 'rightHand_middle_finger_mcp': 41, 'rightHand_middle_finger_pip': 42, 'rightHand_middle_finger_dip': 43, 'rightHand_middle_finger_tip': 44, 'rightHand_ring_finger_mcp': 45, 'rightHand_ring_finger_pip': 46, 'rightHand_ring_finger_dip': 47, 'rightHand_ring_finger_tip': 48, 'rightHand_pinky_mcp': 49, 'rightHand_pinky_pip': 50, 'rightHand_pinky_dip': 51, 'rightHand_pinky_tip': 52, 'pose_chest_middle_up': 53}\n",
      "dict_keys(['pose', 'left_hand', 'rigth_hand'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if augmentation:\n",
    "    train_set = LSP_Dataset(training_set_path, transform=transform, have_aumentation=False,has_normalization=False, keypoints_model='mediapipe',factor=factor_aug)\n",
    "else:\n",
    "    train_set = LSP_Dataset(training_set_path, transform=transform, have_aumentation=True, has_normalization=True,keypoints_model='mediapipe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d8680da-6a70-4a24-8676-8663889391d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "********************\n",
      "Use keypoint model :  mediapipe\n",
      "self.list_labels_banned []\n",
      "path                       : ../SL_ConnectingPoints/split/DGI305-AEC--38--incremental--mediapipe_n_folds_5_seed_1_klod_1-Val.hdf5\n",
      "keypoints_model            : mediapipe\n",
      "landmarks_ref              : Data/Mapeo landmarks librerias.csv\n",
      "threshold_frecuency_labels : 0\n",
      "list_labels_banned         : []\n",
      "Use keypoint model :  mediapipe\n",
      "use column for index keypoint : mp_indexInArray\n",
      " using keypoints_number: 54\n",
      "section_keypoints :  54  -- uniques:  54\n",
      "name_keypoints    :  54  -- uniques:  33\n",
      "idx_keypoints     :  54  -- uniques:  54\n",
      "\n",
      "section_keypoints used:\n",
      "['pose_nose' 'pose_left_eye' 'pose_right_eye' 'pose_left_ear'\n",
      " 'pose_right_ear' 'pose_left_shoulder' 'pose_right_shoulder'\n",
      " 'pose_left_elbow' 'pose_right_elbow' 'pose_left_wrist' 'pose_right_wrist'\n",
      " 'leftHand_wrist' 'leftHand_thumb_cmc' 'leftHand_thumb_mcp'\n",
      " 'leftHand_thumb_ip' 'leftHand_thumb_tip' 'leftHand_index_finger_mcp'\n",
      " 'leftHand_index_finger_pip' 'leftHand_index_finger_dip'\n",
      " 'leftHand_index_finger_tip' 'leftHand_middle_finger_mcp'\n",
      " 'leftHand_middle_finger_pip' 'leftHand_middle_finger_dip'\n",
      " 'leftHand_middle_finger_tip' 'leftHand_ring_finger_mcp'\n",
      " 'leftHand_ring_finger_pip' 'leftHand_ring_finger_dip'\n",
      " 'leftHand_ring_finger_tip' 'leftHand_pinky_mcp' 'leftHand_pinky_pip'\n",
      " 'leftHand_pinky_dip' 'leftHand_pinky_tip' 'rightHand_wrist'\n",
      " 'rightHand_thumb_cmc' 'rightHand_thumb_mcp' 'rightHand_thumb_ip'\n",
      " 'rightHand_thumb_tip' 'rightHand_index_finger_mcp'\n",
      " 'rightHand_index_finger_pip' 'rightHand_index_finger_dip'\n",
      " 'rightHand_index_finger_tip' 'rightHand_middle_finger_mcp'\n",
      " 'rightHand_middle_finger_pip' 'rightHand_middle_finger_dip'\n",
      " 'rightHand_middle_finger_tip' 'rightHand_ring_finger_mcp'\n",
      " 'rightHand_ring_finger_pip' 'rightHand_ring_finger_dip'\n",
      " 'rightHand_ring_finger_tip' 'rightHand_pinky_mcp' 'rightHand_pinky_pip'\n",
      " 'rightHand_pinky_dip' 'rightHand_pinky_tip' 'pose_chest_middle_up']\n",
      "Reading dataset .. \n",
      "Total size dataset :  187\n",
      "Keys in dataset: <KeysViewHDF5 ['0', '1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 187/187 [00:00<00:00, 1328.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size video :  (27, 544, 2) -- label :  DOS\n",
      "filtering by keypoints idx .. \n",
      "filtered size video :  (27, 54, 2) -- label :  DOS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frecuency labels filtering ...\n",
      "hist counter\n",
      "{'DOS': 9, 'COMPRAR': 3, 'UNO': 6, 'IGUAL': 7, 'COMER': 9, 'HACER': 4, 'CIEN': 7, 'DENTRO': 4, 'BIEN': 9, 'IDEA': 4, 'CASA': 3, 'PENSAR': 8, 'NIÑO': 4, 'AYUDAR': 4, 'GUARDAR': 3, 'NO': 7, 'HOLA': 3, 'DECIR': 7, 'DORMIR': 5, 'AMIGO': 3, 'YO': 9, 'SENTIR': 3, 'TRES': 5, 'CAMINAR-PERSONA': 6, 'ESCRIBIR': 3, 'YA': 5, 'QUÉ': 3, 'AHORA': 5, 'MI': 4, 'SOL': 2, 'SABER': 2, 'OYE': 3, 'VER': 9, 'DINERO': 3, 'HOY': 4, 'IR': 5, 'ESPERAR': 4, 'CUANTO': 3}\n",
      "sorted(set(labels_dataset))  :  ['AHORA', 'AMIGO', 'AYUDAR', 'BIEN', 'CAMINAR-PERSONA', 'CASA', 'CIEN', 'COMER', 'COMPRAR', 'CUANTO', 'DECIR', 'DENTRO', 'DINERO', 'DORMIR', 'DOS', 'ESCRIBIR', 'ESPERAR', 'GUARDAR', 'HACER', 'HOLA', 'HOY', 'IDEA', 'IGUAL', 'IR', 'MI', 'NIÑO', 'NO', 'OYE', 'PENSAR', 'QUÉ', 'SABER', 'SENTIR', 'SOL', 'TRES', 'UNO', 'VER', 'YA', 'YO']\n",
      "dict_labels_dataset      : {'AHORA': 0, 'AMIGO': 1, 'AYUDAR': 2, 'BIEN': 3, 'CAMINAR-PERSONA': 4, 'CASA': 5, 'CIEN': 6, 'COMER': 7, 'COMPRAR': 8, 'CUANTO': 9, 'DECIR': 10, 'DENTRO': 11, 'DINERO': 12, 'DORMIR': 13, 'DOS': 14, 'ESCRIBIR': 15, 'ESPERAR': 16, 'GUARDAR': 17, 'HACER': 18, 'HOLA': 19, 'HOY': 20, 'IDEA': 21, 'IGUAL': 22, 'IR': 23, 'MI': 24, 'NIÑO': 25, 'NO': 26, 'OYE': 27, 'PENSAR': 28, 'QUÉ': 29, 'SABER': 30, 'SENTIR': 31, 'SOL': 32, 'TRES': 33, 'UNO': 34, 'VER': 35, 'YA': 36, 'YO': 37}\n",
      "inv_dict_labels_dataset  : {0: 'AHORA', 1: 'AMIGO', 2: 'AYUDAR', 3: 'BIEN', 4: 'CAMINAR-PERSONA', 5: 'CASA', 6: 'CIEN', 7: 'COMER', 8: 'COMPRAR', 9: 'CUANTO', 10: 'DECIR', 11: 'DENTRO', 12: 'DINERO', 13: 'DORMIR', 14: 'DOS', 15: 'ESCRIBIR', 16: 'ESPERAR', 17: 'GUARDAR', 18: 'HACER', 19: 'HOLA', 20: 'HOY', 21: 'IDEA', 22: 'IGUAL', 23: 'IR', 24: 'MI', 25: 'NIÑO', 26: 'NO', 27: 'OYE', 28: 'PENSAR', 29: 'QUÉ', 30: 'SABER', 31: 'SENTIR', 32: 'SOL', 33: 'TRES', 34: 'UNO', 35: 'VER', 36: 'YA', 37: 'YO'}\n",
      "encoded_dataset: 187\n",
      "label encoding completed!\n",
      "total unique labels :  38\n",
      "Reading dataset completed!\n",
      "{'pose': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 53], 'left_hand': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], 'rigth_hand': [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]} {'pose_nose': 0, 'pose_left_eye': 1, 'pose_right_eye': 2, 'pose_left_ear': 3, 'pose_right_ear': 4, 'pose_left_shoulder': 5, 'pose_right_shoulder': 6, 'pose_left_elbow': 7, 'pose_right_elbow': 8, 'pose_left_wrist': 9, 'pose_right_wrist': 10, 'leftHand_wrist': 11, 'leftHand_thumb_cmc': 12, 'leftHand_thumb_mcp': 13, 'leftHand_thumb_ip': 14, 'leftHand_thumb_tip': 15, 'leftHand_index_finger_mcp': 16, 'leftHand_index_finger_pip': 17, 'leftHand_index_finger_dip': 18, 'leftHand_index_finger_tip': 19, 'leftHand_middle_finger_mcp': 20, 'leftHand_middle_finger_pip': 21, 'leftHand_middle_finger_dip': 22, 'leftHand_middle_finger_tip': 23, 'leftHand_ring_finger_mcp': 24, 'leftHand_ring_finger_pip': 25, 'leftHand_ring_finger_dip': 26, 'leftHand_ring_finger_tip': 27, 'leftHand_pinky_mcp': 28, 'leftHand_pinky_pip': 29, 'leftHand_pinky_dip': 30, 'leftHand_pinky_tip': 31, 'rightHand_wrist': 32, 'rightHand_thumb_cmc': 33, 'rightHand_thumb_mcp': 34, 'rightHand_thumb_ip': 35, 'rightHand_thumb_tip': 36, 'rightHand_index_finger_mcp': 37, 'rightHand_index_finger_pip': 38, 'rightHand_index_finger_dip': 39, 'rightHand_index_finger_tip': 40, 'rightHand_middle_finger_mcp': 41, 'rightHand_middle_finger_pip': 42, 'rightHand_middle_finger_dip': 43, 'rightHand_middle_finger_tip': 44, 'rightHand_ring_finger_mcp': 45, 'rightHand_ring_finger_pip': 46, 'rightHand_ring_finger_dip': 47, 'rightHand_ring_finger_tip': 48, 'rightHand_pinky_mcp': 49, 'rightHand_pinky_pip': 50, 'rightHand_pinky_dip': 51, 'rightHand_pinky_tip': 52, 'pose_chest_middle_up': 53}\n",
      "dict_keys(['pose', 'left_hand', 'rigth_hand'])\n"
     ]
    }
   ],
   "source": [
    "val_set = LSP_Dataset(validation_set_path, keypoints_model='mediapipe', have_aumentation=False,has_normalization=True)\n",
    "val_loader = DataLoader(val_set, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a1e77c6-91e2-43f8-9063-5f83409900b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if augmentation:\n",
    "    train_loader = AugmentedDataLoader(train_set, shuffle=True, generator=g)\n",
    "else:\n",
    "    train_loader = DataLoader(train_set, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e946114-0cc2-4025-9445-5fdcfe12b48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Src.datasets.Spoter_dataloader_aug.AugmentedDataLoader at 0x7f9be763eb20>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f88f7ca-ac24-4963-bc53-db46e70e3773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f9be7674280>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dde1222a-d9f8-4754-a04c-9866f7799eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader.dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec3310e8-4ed5-400f-a3af-72c2537b95e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Otra opción:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth_map, label, video_name \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Mostrar valores \u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_name : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Gloss/Spoter-SL/Notebooks/../Src/datasets/Spoter_dataloader_aug.py:63\u001b[0m, in \u001b[0;36mAugmentedDataLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         sample \u001b[38;5;241m=\u001b[39m (depth_map, label, video_name)\n\u001b[1;32m     61\u001b[0m         batch\u001b[38;5;241m.\u001b[39mappend(sample)\n\u001b[0;32m---> 63\u001b[0m depth_maps, labels, video_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(depth_maps), torch\u001b[38;5;241m.\u001b[39mstack(labels), video_names\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "# Otra opción:\n",
    "for depth_map, label, video_name in train_loader:\n",
    "    # Mostrar valores \n",
    "    print(f\"video_name : {video_name}\")\n",
    "    print(f\"label      : {label}\")\n",
    "    print(f\"depth_map  : {depth_map}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c040f674-db5f-404a-b73e-ff2bf57cb975",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Obtener un batch \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m depth_map, label, video_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Mostrar valores \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_name : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Gloss/Spoter-SL/Notebooks/../Src/datasets/Spoter_dataloader_aug.py:63\u001b[0m, in \u001b[0;36mAugmentedDataLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         sample \u001b[38;5;241m=\u001b[39m (depth_map, label, video_name)\n\u001b[1;32m     61\u001b[0m         batch\u001b[38;5;241m.\u001b[39mappend(sample)\n\u001b[0;32m---> 63\u001b[0m depth_maps, labels, video_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(depth_maps), torch\u001b[38;5;241m.\u001b[39mstack(labels), video_names\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "# Obtener un batch \n",
    "depth_map, label, video_name = next(iter(train_loader))\n",
    "\n",
    "# Mostrar valores \n",
    "print(f\"video_name : {video_name}\")\n",
    "print(f\"label      : {label}\")\n",
    "print(f\"depth_map  : {depth_map}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c498bcd-bc6c-4826-a6cd-ce25172f1a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
